{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import Sklearn model libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_score, recall_score, precision_recall_curve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# Import Utility libraries\n",
    "import shap\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "import ipyparallel as ipp\n",
    "import time\n",
    "from termcolor import colored\n",
    "import os\n",
    "# Attack Utilities\n",
    "# from create_models import create_models\n",
    "# from attack import attack\n",
    "# from attack_utils import baseline, load_data\n",
    "# from attack_data import attack_dataset, run_engines\n",
    "\n",
    "# Pre-run necessities\n",
    "warnings.filterwarnings('ignore')\n",
    "rnds = [60, 452, 774, 802, 961, 626, 726, 211, 375, 448, 883, 684, 724, 333, 64, 646, 116, 714, 483, 73, 562, 703, 276, 394, 190, 675, 314, 604, 297, 266, 456, 845, 822, 529, 420, 605, 935, 733, 167, 603, 401, 948, 241, 734, 550, 65, 429, 470, 633, 627, 223, 713, 958, 40, 200, 641, 357, 778, 781, 498, 202, 349, 983, 125, 548, 331, 206, 556, 356, 805, 246, 626, 358, 393, 307, 792, 777, 169, 595, 279, 719, 902, 124, 197, 983, 499, 368, 864, 896, 887, 879, 224, 220, 926, 565, 173, 919, 3, 908, 941]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(run,dataset_name,at_type):\n",
    "    influence_types = ['SHAP','DP_impurity','DP_importance']\n",
    "    for influence_type in influence_types:\n",
    "        if at_type == '1':\n",
    "            parent_dir = '/home/amanmoha/influence_attack/results/actual/RF/modules/'\n",
    "        elif at_type == '2':\n",
    "            parent_dir = '/home/amanmoha/influence_attack/results/actual/RF/modules_ref_tuning/'\n",
    "\n",
    "        directory = 'run'+run+'/'+dataset_name+'/'+influence_type\n",
    "        path = os.path.join(parent_dir,directory)\n",
    "\n",
    "        with open(path+'/data.txt','rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        f.close()\n",
    "        tar_val_,tar_lab_,ref_val_,ref_lab_,true_labels_ = data[0],data[1],data[2],data[3],data[4]\n",
    "        try:\n",
    "            tar_val = np.concatenate((tar_val,tar_val_),axis=-1)\n",
    "            ref_val = np.concatenate((ref_val,ref_val_),axis=-1)\n",
    "        except NameError:\n",
    "            tar_val,tar_lab,ref_val,ref_lab,true_labels = tar_val_,tar_lab_,ref_val_,ref_lab_,true_labels_\n",
    "\n",
    "    return tar_val,tar_lab,ref_val,ref_lab,true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attack():\n",
    "    \n",
    "    def __init__(self,r,want_tune,tune_scoring):\n",
    "        self.rs = r\n",
    "        self.want_tune=want_tune\n",
    "        self.tune_scoring=tune_scoring\n",
    "    \n",
    "    def set_parameters(self,model,x,y):\n",
    "        params = {'n_estimators':[20,50,100,150,200],'max_depth':[3,4,5,6,7]}\n",
    "        grid_search = GridSearchCV(model,params,scoring=self.tune_scoring,n_jobs=-1)\n",
    "        grid_search.fit(x,y)\n",
    "        best_parameters = grid_search.best_params_\n",
    "        return best_parameters\n",
    "\n",
    "    def fit(self,x,y):\n",
    "        self.attack_model = RandomForestClassifier(random_state=self.rs)\n",
    "        if self.want_tune:\n",
    "            best_params = self.set_parameters(self.attack_model,x,y)\n",
    "            self.attack_model.set_params(n_estimators = best_params['n_estimators'])\n",
    "            self.attack_model.set_params(max_depth = best_params['max_depth'])\n",
    "#             print(colored(\"Best parameters - Attack model\",'blue'),end=\": \")\n",
    "#             print('n_estimators= {a}, max_depth= {b}\\n'.format(a=best_params['n_estimators'],b=best_params['max_depth']))\n",
    "        self.attack_model.fit(x,y)\n",
    "    \n",
    "    def predict(self,x):\n",
    "        return self.attack_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(tar_model,target_data,tar_lab,true_lab):\n",
    "    preds = tar_model.predict(target_data)\n",
    "    mem_preds = np.ones(preds.shape[0])\n",
    "    mem_preds[preds!=true_lab]=0\n",
    "    acc_sc = accuracy_score(tar_lab,mem_preds)\n",
    "    pr_sc = precision_score(tar_lab,mem_preds)\n",
    "    rec_sc = recall_score(tar_lab,mem_preds)\n",
    "    f1_sc =f1_score(tar_lab,mem_preds)\n",
    "\n",
    "    return acc_sc,pr_sc,rec_sc,f1_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d2f34e591c4747b0325980375821ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Datasets', max=1, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m###################################################\u001b[0m\n",
      "\u001b[34mDataset used: \u001b[0m adult_income\n",
      "\u001b[34m###################################################\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee83773aa19b4164926feddb17897a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Different random states', max=15, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m################# RESULTS #################\n",
      "\u001b[0m\n",
      "Target train accuracy:\t 0.0\n",
      "Target test accuracy:\t 0.0\n",
      "Attack accuracy:\t 0.5231466666666668\n",
      "Attack precision:\t 0.5276116643761242\n",
      "Attack recall:\t\t 0.4449866666666667\n",
      "Attack f1:\t\t 0.467391100334763\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# DRIVER\n",
    "###################\n",
    "'''\n",
    "DATASET NAMES: adult_income, bcw, german_credit, pima_diabetes, hepatitis, heart_disease\n",
    "KNOWLEGDE: disjoint, shared\n",
    "INFLUENCE TYPE: SHAP, DP_impurity, DP_threshold, DP_importance, DP_nodesamples\n",
    "DOUBLE INFLUENCE: False, True\n",
    "'''\n",
    "\n",
    "## INITIALIZATIONS\n",
    "dataset_names = ['adult_income']\n",
    "attack_params = {'tuning':True,\n",
    "                'scoring':'f1'}\n",
    "run = '5'\n",
    "at_type = '2'\n",
    "\n",
    "for dataset_name in tqdm_notebook(dataset_names,desc=\"Datasets\"):\n",
    "    tar_val,tar_lab,ref_val,ref_lab,true_labels = read_file(run,dataset_name,at_type)\n",
    "    ac,ps,rs,fs,tr_ac,te_ac=0,0,0,0,0,0\n",
    "\n",
    "    #################################\n",
    "    # print information to screen\n",
    "    #################################\n",
    "    print(colored(\"###################################################\",'blue'))\n",
    "    print(colored(\"Dataset used: \",'blue'), dataset_name)\n",
    "    print(colored(\"###################################################\\n\",'blue'))\n",
    "    n_states = tar_val.shape[0]\n",
    "    for i in tqdm_notebook(range(n_states),desc='Different random states'):\n",
    "\n",
    "        obj = attack(rnds[0],want_tune=attack_params['tuning'],tune_scoring=attack_params['scoring'])\n",
    "        obj.fit(np.squeeze(ref_val[i]),np.squeeze(ref_lab[i]))\n",
    "        preds = obj.predict(np.squeeze(tar_val[i]))\n",
    "        ## METRICS RECORD\n",
    "        ac+=accuracy_score(np.squeeze(tar_lab[i]),preds)\n",
    "        ps+=precision_score(np.squeeze(tar_lab[i]),preds)\n",
    "        rs+=recall_score(np.squeeze(tar_lab[i]),preds)\n",
    "        fs+=f1_score(np.squeeze(tar_lab[i]),preds)\n",
    "\n",
    "    print(colored(\"################# RESULTS #################\\n\",'blue'))\n",
    "    print(\"Target train accuracy:\\t {a}\\nTarget test accuracy:\\t {b}\\nAttack accuracy:\\t {c}\\nAttack precision:\\t {d}\\nAttack recall:\\t\\t {e}\\nAttack f1:\\t\\t {f}\\n\".format(a=tr_ac/n_states,b=te_ac/n_states,c=ac/n_states,d=ps/n_states,e=rs/n_states,f=fs/n_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
